<title>3D Orb Audio Visualization</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            background-color: #000;
            font-family: Arial, sans-serif;
        }
        #controls {
            position: fixed;
            top: 20px;
            left: 20px;
            z-index: 10;
            color: white;
            background-color: rgba(0, 0, 0, 0.5);
            padding: 15px;
            border-radius: 10px;
            max-width: 350px;
            max-height: 80vh;
            overflow-y: auto;
        }
        button {
            background-color: #4CAF50;
            border: none;
            color: white;
            padding: 8px 16px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 14px;
            margin: 4px 2px;
            cursor: pointer;
            border-radius: 4px;
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        #stopBtn {
            background-color: #f44336;
        }
        #status {
            margin-top: 10px;
        }
        .form-group {
            margin-bottom: 15px;
        }
        label {
            display: block;
            margin-bottom: 5px;
            font-weight: bold;
        }
        input[type="text"], select, textarea {
            width: 100%;
            padding: 8px;
            border: 1px solid #ddd;
            border-radius: 4px;
            box-sizing: border-box;
            background-color: rgba(255, 255, 255, 0.9);
        }
        textarea {
            height: 80px;
            resize: vertical;
        }
        .tab-container {
            margin-top: 15px;
        }
        .tab {
            overflow: hidden;
            border-bottom: 1px solid #ccc;
            margin-bottom: 10px;
        }
        .tab button {
            background-color: inherit;
            float: left;
            border: none;
            outline: none;
            cursor: pointer;
            padding: 8px 16px;
            transition: 0.3s;
            color: #ddd;
        }
        .tab button:hover {
            background-color: rgba(255, 255, 255, 0.1);
        }
        .tab button.active {
            background-color: rgba(255, 255, 255, 0.2);
            color: white;
        }
        .tabcontent {
            display: none;
            padding: 10px 0;
        }
        .error {
            color: #ff6b6b;
            font-weight: bold;
            margin-top: 10px;
        }
        /* Improved slider styling */
        .slider-container {
            margin-top: 10px;
            position: relative;
        }
        .slider-labels {
            display: flex;
            justify-content: space-between;
            margin-bottom: 5px;
            font-size: 12px;
            color: #ddd;
        }
        input[type="range"] {
            width: 100%;
            margin: 0;
            background: transparent;
            -webkit-appearance: none;
        }
        input[type="range"]:focus {
            outline: none;
        }
        input[type="range"]::-webkit-slider-runnable-track {
            width: 100%;
            height: 6px;
            cursor: pointer;
            background: rgba(255, 255, 255, 0.3);
            border-radius: 3px;
        }
        input[type="range"]::-webkit-slider-thumb {
            height: 16px;
            width: 16px;
            border-radius: 50%;
            background: #4CAF50;
            cursor: pointer;
            -webkit-appearance: none;
            margin-top: -5px;
        }
        input[type="range"]::-moz-range-track {
            width: 100%;
            height: 6px;
            cursor: pointer;
            background: rgba(255, 255, 255, 0.3);
            border-radius: 3px;
        }
        input[type="range"]::-moz-range-thumb {
            height: 16px;
            width: 16px;
            border-radius: 50%;
            background: #4CAF50;
            cursor: pointer;
        }
        .speed-value-display {
            position: relative;
            text-align: center;
            font-weight: bold;
            color: white;
            margin-top: 5px;
            font-size: 14px;
        }
        /* Add tab styling if not already present */
        .tab {
            overflow: hidden;
            background-color: #333;
            border-radius: 5px 5px 0 0;
        }

        .tab button {
            background-color: inherit;
            float: left;
            border: none;
            outline: none;
            cursor: pointer;
            padding: 14px 16px;
            transition: 0.3s;
            color: white;
        }

        .tab button:hover {
            background-color: #555;
        }

        .tab button.active {
            background-color: #4CAF50;
        }

        .tabcontent {
            display: none;
            padding: 20px;
            border-top: none;
        }

        /* WebRTC specific styles */
        #streamStatus {
            margin-top: 10px;
            color: #4CAF50;
            font-weight: bold;
        }

        #startStreamBtn {
            background-color: #4CAF50;
        }

        #startStreamBtn.streaming {
            background-color: #f44336;
        }
    </style>
</head>
<body>

    <div id="controls">
        <h1>MLX-Audio Player</h1>

        <div class="tab">
            <button class="tablinks active" onclick="openTab(event, 'textToSpeech')">Text to Speech</button>
            <button class="tablinks" onclick="openTab(event, 'fileUpload')">File Upload</button>
            <button class="tablinks" onclick="openTab(event, 'speechToSpeech')">Speech to Speech</button>
        </div>

        <div id="textToSpeech" class="tabcontent" style="display: block;">
            <div class="form-group">
                <label for="modelType">Model Type:</label>
                <select id="modelType">
                    <!-- Options will be loaded from server -->
                </select>
            </div>

            <div class="form-group">
                <label for="model">Model Variant:</label>
                <select id="model">
                    <!-- Options will be loaded based on selected model type -->
                </select>
            </div>

            <div class="form-group">
                <label for="text">Text to convert:</label>
                <textarea id="text" placeholder="Enter text here..."></textarea>
            </div>

            <div class="form-group" id="languageGroup">
                <label for="language">Language:</label>
                <select id="language">
                    <!-- Options will be populated dynamically based on model -->
                </select>
            </div>

            <div class="form-group" id="voiceGroup">
                <label for="voice">Voice:</label>
                <select id="voice">
                    <!-- Options will be populated dynamically based on model and language -->
                </select>
            </div>

            <div class="form-group" id="referenceAudioGroup" style="display: none;">
                <label for="referenceAudio">Reference Audio (for voice cloning):</label>
                <input type="file" id="referenceAudio" accept="audio/*">
                <small style="color: #999;">Upload an audio file to clone its voice</small>
            </div>

            <div class="form-group" id="speedGroup">
                <label for="speed">Speech Speed:</label>
                <div class="slider-container" id="normalSpeedContainer">
                    <div class="slider-labels">
                        <span>Slower</span>
                        <span>Normal</span>
                        <span>Faster</span>
                    </div>
                    <input type="range" id="speed" min="0.5" max="2.0" step="0.1" value="1.0">
                    <div class="speed-value-display"><span id="speed-value">1.0</span>x</div>
                </div>
                <select id="sparkSpeed" style="display: none; width: 100%;">
                    <option value="very_low">Very Slow</option>
                    <option value="low">Slow</option>
                    <option value="moderate" selected>Normal</option>
                    <option value="high">Fast</option>
                    <option value="very_high">Very Fast</option>
                </select>
            </div>
            
            <div class="form-group" id="pitchGroup" style="display: none;">
                <label for="sparkPitch">Voice Pitch:</label>
                <select id="sparkPitch" style="width: 100%;">
                    <option value="very_low">Very Low</option>
                    <option value="low">Low</option>
                    <option value="moderate" selected>Normal</option>
                    <option value="high">High</option>
                    <option value="very_high">Very High</option>
                </select>
            </div>
            
            <div class="form-group" id="genderGroup" style="display: none;">
                <label for="sparkGender">Voice Gender:</label>
                <select id="sparkGender" style="width: 100%;">
                    <option value="female" selected>Female</option>
                    <option value="male">Male</option>
                </select>
            </div>

            <button id="generateBtn">Generate Speech</button>
            <button id="openFolderBtn" style="background-color: #2196F3;">Open Output Folder</button>
            <div id="ttsError" class="error" style="display: none;"></div>
            <div id="ttsStatus" style="margin-top: 10px; max-width: 350px;"></div>
        </div>

        <div id="fileUpload" class="tabcontent">
            <input type="file" id="audioUpload" accept="audio/*">
            <div style="margin-top: 10px;">
                <button id="playBtn" disabled>Play</button>
                <button id="stopBtn" disabled>Stop</button>
            </div>
            <div id="status">Upload an audio file to begin visualization</div>
        </div>

        <!-- Speech to Speech Tab (New) -->
        <div id="speechToSpeech" class="tabcontent">
            <h3>Real-time Speech Conversion</h3>

            <div>
                <label for="s2sVoice">Voice:</label>
                <select id="s2sVoice" class="form-control">
                    <option value="af_bella">AF Bella</option>
                    <option value="af_heart">AF Heart</option>
                    <option value="af_nicole">AF Nicole</option>
                    <option value="af_nova">AF Nova</option>
                    <option value="af_sarah">AF Sarah</option>
                    <option value="af_sky">AF Sky</option>
                    <option value="am_adam">AM Adam</option>
                    <option value="am_michael">AM Michael</option>
                    <option value="bf_emma">BF Emma</option>
                    <option value="bf_isabella">BF Isabella</option>
                    <option value="bm_george">BM George</option>
                    <option value="bm_lewis">BM Lewis</option>
                </select>
            </div>

            <div>
                <label for="s2sModel">Model:</label>
                <select id="s2sModel" class="form-control">
                    <option value="kokoro_82m_4bit">Kokoro 82M 4bit</option>
                </select>
            </div>

            <div>
                <label for="s2sSpeed">Speech Speed:</label>
                <div class="speed-control">
                    <span>Slower</span>
                    <input type="range" id="s2sSpeed" min="0.5" max="2.0" step="0.1" value="1.0">
                    <span>Faster</span>
                </div>
                <div id="s2sSpeedValue">1.0x</div>
            </div>

            <button id="startStreamBtn">Start Stream</button>
            <div id="streamStatus"></div>
        </div>
        <audio id="audioElement" autoplay style="display: none;"></audio>
    </div>

    <!-- Load Three.js from CDN -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/controls/OrbitControls.js"></script>

    <script>
        // DOM elements
        const audioUpload = document.getElementById('audioUpload');
        const playBtn = document.getElementById('playBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusElement = document.getElementById('status');

        // TTS elements
        const textInput = document.getElementById('text');
        const languageSelect = document.getElementById('language');
        const voiceSelect = document.getElementById('voice');
        const modelTypeSelect = document.getElementById('modelType');
        const modelSelect = document.getElementById('model');
        const referenceAudioGroup = document.getElementById('referenceAudioGroup');
        const referenceAudioInput = document.getElementById('referenceAudio');
        
        // Model-specific language configurations
        const languagesByModel = {
            'kokoro': [
                {value: 'a', text: 'ðŸ‡ºðŸ‡¸ American English'},
                {value: 'b', text: 'ðŸ‡¬ðŸ‡§ British English'},
                {value: 'e', text: 'ðŸ‡ªðŸ‡¸ Spanish'},
                {value: 'f', text: 'ðŸ‡«ðŸ‡· French'},
                {value: 'h', text: 'ðŸ‡®ðŸ‡³ Hindi'},
                {value: 'i', text: 'ðŸ‡®ðŸ‡¹ Italian'},
                {value: 'p', text: 'ðŸ‡§ðŸ‡· Portuguese (Brazilian)'},
                {value: 'j', text: 'ðŸ‡¯ðŸ‡µ Japanese'},
                {value: 'z', text: 'ðŸ‡¨ðŸ‡³ Mandarin Chinese'}
            ],
            'csm': [], // No language selection for CSM
            'spark': [] // Spark doesn't have language selection
        };

        // Model-specific voice configurations
        const voicesByModel = {
            'kokoro': {
                'a': [ // American English
                {value: 'af_heart', text: 'Heart (Female)'},
                {value: 'af_alloy', text: 'Alloy (Female)'},
                {value: 'af_aoede', text: 'Aoede (Female)'},
                {value: 'af_bella', text: 'Bella (Female)'},
                {value: 'af_jessica', text: 'Jessica (Female)'},
                {value: 'af_kore', text: 'Kore (Female)'},
                {value: 'af_nicole', text: 'Nicole (Female)'},
                {value: 'af_nova', text: 'Nova (Female)'},
                {value: 'af_river', text: 'River (Female)'},
                {value: 'af_sarah', text: 'Sarah (Female)'},
                {value: 'af_sky', text: 'Sky (Female)'},
                {value: 'am_adam', text: 'Adam (Male)'},
                {value: 'am_echo', text: 'Echo (Male)'},
                {value: 'am_eric', text: 'Eric (Male)'},
                {value: 'am_fenrir', text: 'Fenrir (Male)'},
                {value: 'am_liam', text: 'Liam (Male)'},
                {value: 'am_michael', text: 'Michael (Male)'},
                {value: 'am_onyx', text: 'Onyx (Male)'},
                {value: 'am_puck', text: 'Puck (Male)'},
                {value: 'am_santa', text: 'Santa (Male)'}
            ],
            'b': [ // British English
                {value: 'bf_alice', text: 'Alice (Female)'},
                {value: 'bf_emma', text: 'Emma (Female)'},
                {value: 'bf_isabella', text: 'Isabella (Female)'},
                {value: 'bf_lily', text: 'Lily (Female)'},
                {value: 'bm_daniel', text: 'Daniel (Male)'},
                {value: 'bm_fable', text: 'Fable (Male)'},
                {value: 'bm_george', text: 'George (Male)'},
                {value: 'bm_lewis', text: 'Lewis (Male)'}
            ],
            'e': [ // Spanish
                {value: 'ef_dora', text: 'Dora (Female)'},
                {value: 'em_alex', text: 'Alex (Male)'},
                {value: 'em_santa', text: 'Santa (Male)'}
            ],
            'f': [ // French
                {value: 'ff_siwis', text: 'Siwis (Female)'}
            ],
            'h': [ // Hindi
                {value: 'hf_alpha', text: 'Alpha (Female)'},
                {value: 'hf_beta', text: 'Beta (Female)'},
                {value: 'hm_omega', text: 'Omega (Male)'},
                {value: 'hm_psi', text: 'Psi (Male)'}
            ],
            'i': [ // Italian
                {value: 'if_sara', text: 'Sara (Female)'},
                {value: 'im_nicola', text: 'Nicola (Male)'}
            ],
            'p': [ // Portuguese (Brazilian)
                {value: 'pf_dora', text: 'Dora (Female)'},
                {value: 'pm_alex', text: 'Alex (Male)'},
                {value: 'pm_santa', text: 'Santa (Male)'}
            ],
            'j': [ // Japanese
                {value: 'jf_alpha', text: 'Alpha (Female)'},
                {value: 'jf_gongitsune', text: 'Gongitsune (Female)'},
                {value: 'jf_nezumi', text: 'Nezumi (Female)'},
                {value: 'jf_tebukuro', text: 'Tebukuro (Female)'},
                {value: 'jm_kumo', text: 'Kumo (Male)'}
            ],
            'z': [ // Mandarin Chinese
                {value: 'zf_xiaobei', text: 'Xiaobei (Female)'},
                {value: 'zf_xiaoni', text: 'Xiaoni (Female)'},
                {value: 'zf_xiaoxiao', text: 'Xiaoxiao (Female)'},
                {value: 'zf_xiaoyi', text: 'Xiaoyi (Female)'},
                {value: 'zm_yunjian', text: 'Yunjian (Male)'},
                {value: 'zm_yunxi', text: 'Yunxi (Male)'},
                {value: 'zm_yunxia', text: 'Yunxia (Male)'},
                {value: 'zm_yunyang', text: 'Yunyang (Male)'}
            ]
            },
            'spark': {
                'default': [
                    {value: 'default', text: 'Default Voice'}
                ]
            },
            'csm': {
                'default': [] // CSM uses reference audio for voice
            }
        };
        
        // Function to update language options based on selected model
        function updateLanguageOptions() {
            const selectedModel = modelTypeSelect.value;
            const languages = languagesByModel[selectedModel] || [];
            const languageGroup = document.getElementById('languageGroup');
            
            // Clear current options
            languageSelect.innerHTML = '';
            
            if (languages.length > 0) {
                languageGroup.style.display = 'block';
                languages.forEach(lang => {
                    const option = document.createElement('option');
                    option.value = lang.value;
                    option.textContent = lang.text;
                    languageSelect.appendChild(option);
                });
                // Trigger voice update for the default language
                updateVoiceOptions();
            } else {
                languageGroup.style.display = 'none';
                // Still update voices for models without language selection
                updateVoiceOptions();
            }
        }
        
        // Function to update voice options based on selected model and language
        function updateVoiceOptions() {
            const selectedModel = modelTypeSelect.value;
            const selectedLanguage = languageSelect.value;
            const voiceGroup = document.getElementById('voiceGroup');
            
            let voices = [];
            
            if (voicesByModel[selectedModel]) {
                if (selectedLanguage && voicesByModel[selectedModel][selectedLanguage]) {
                    voices = voicesByModel[selectedModel][selectedLanguage];
                } else if (voicesByModel[selectedModel]['default']) {
                    voices = voicesByModel[selectedModel]['default'];
                }
            }
            
            // Clear current options
            voiceSelect.innerHTML = '';
            
            if (voices.length > 0) {
                voiceGroup.style.display = 'block';
                voices.forEach(voice => {
                    const option = document.createElement('option');
                    option.value = voice.value;
                    option.textContent = voice.text;
                    voiceSelect.appendChild(option);
                });
            } else {
                // Hide voice selection for models that don't use predefined voices
                if (selectedModel === 'csm') {
                    voiceGroup.style.display = 'none';
                } else {
                    voiceGroup.style.display = 'block';
                }
            }
        }
        
        // Model configurations - will be fetched from server
        let modelConfigs = {};
        
        // Fetch models from server
        async function fetchModels() {
            try {
                const response = await fetch('/models');
                const data = await response.json();
                
                // Clear and rebuild model type dropdown
                modelTypeSelect.innerHTML = '';
                
                // Convert server response to our format
                data.models.forEach(model => {
                    // Add option to model type dropdown
                    const option = document.createElement('option');
                    option.value = model.id;
                    option.textContent = `${model.name} (${model.description})`;
                    modelTypeSelect.appendChild(option);
                    
                    // Store model config
                    modelConfigs[model.id] = {
                        variants: model.variants.map(v => ({
                            value: v.value,
                            text: v.name || v.text
                        })),
                        supportsLanguages: model.supports_languages,
                        supportsVoices: model.supports_voices,
                        supportsReferenceAudio: model.supports_reference_audio
                    };
                });
                
                // Initialize with first model
                if (data.models.length > 0) {
                    updateModelVariants();
                    updateSparkControls();
                }
            } catch (error) {
                console.error('Failed to fetch models:', error);
                // Fallback to hardcoded if server fails
                modelConfigs = {
                    'kokoro': {
                        variants: [
                            {value: 'mlx-community/Kokoro-82M-4bit', text: 'Kokoro 82M (4-bit)'}
                        ],
                        supportsLanguages: true,
                        supportsVoices: true,
                        supportsReferenceAudio: false
                    }
                };
            }
        }

        // Function to update model variants
        function updateModelVariants() {
            const selectedType = modelTypeSelect.value;
            const config = modelConfigs[selectedType];
            
            // Check if config exists
            if (!config) {
                console.warn('No config found for model:', selectedType);
                return;
            }
            
            // Clear current options
            modelSelect.innerHTML = '';
            
            // Add new options
            config.variants.forEach(variant => {
                const option = document.createElement('option');
                option.value = variant.value;
                option.textContent = variant.text;
                modelSelect.appendChild(option);
            });
            
            // Show/hide reference audio based on model capabilities
            if (config.supportsReferenceAudio) {
                referenceAudioGroup.style.display = 'block';
            } else {
                referenceAudioGroup.style.display = 'none';
            }
            
            // Update language and voice options
            updateLanguageOptions();
        }

        // Update voices when language changes
        languageSelect.addEventListener('change', updateVoiceOptions);
        
        // Update model variants when model type changes
        modelTypeSelect.addEventListener('change', function() {
            updateModelVariants();
            updateSparkControls();
        });
        
        // Function to update controls based on whether Spark is selected
        function updateSparkControls() {
            const selectedType = modelTypeSelect.value;
            
            // Check if we have models loaded
            if (!selectedType || Object.keys(modelConfigs).length === 0) {
                return;
            }
            
            const normalSpeedContainer = document.getElementById('normalSpeedContainer');
            const sparkSpeedSelect = document.getElementById('sparkSpeed');
            const pitchGroup = document.getElementById('pitchGroup');
            const genderGroup = document.getElementById('genderGroup');
            
            if (selectedType === 'spark') {
                // Show Spark-specific controls
                normalSpeedContainer.style.display = 'none';
                sparkSpeedSelect.style.display = 'block';
                pitchGroup.style.display = 'block';
                genderGroup.style.display = 'block';
                // Hide voice selection for Spark
                document.getElementById('voiceGroup').style.display = 'none';
            } else {
                // Show normal controls
                normalSpeedContainer.style.display = 'block';
                sparkSpeedSelect.style.display = 'none';
                pitchGroup.style.display = 'none';
                genderGroup.style.display = 'none';
                // Show voice selection for other models
                if (modelConfigs[selectedType] && modelConfigs[selectedType].supportsVoices) {
                    document.getElementById('voiceGroup').style.display = 'block';
                }
            }
        }
        
        const speedInput = document.getElementById('speed');
        const speedValue = document.getElementById('speed-value');
        const generateBtn = document.getElementById('generateBtn');
        const openFolderBtn = document.getElementById('openFolderBtn');
        const ttsErrorElement = document.getElementById('ttsError');
        const ttsStatusElement = document.getElementById('ttsStatus');

        // Audio variables
        let audioContext;
        let analyser;
        let dataArray;
        let audioElement = document.getElementById('audioElement');
        let audioSource;

        // Three.js setup
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setClearColor(0x000000);
        document.body.appendChild(renderer.domElement);

        // Add orbit controls
        const controls = new THREE.OrbitControls(camera, renderer.domElement);
        controls.enableDamping = true;
        controls.dampingFactor = 0.05;

        // Position camera
        camera.position.set(0, 0, 100);
        camera.lookAt(0, 0, 0);

        // Add lights
        const ambientLight = new THREE.AmbientLight(0x404040);
        scene.add(ambientLight);

        const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
        directionalLight.position.set(1, 1, 1);
        scene.add(directionalLight);

        const pointLight = new THREE.PointLight(0xffffff, 1, 100);
        pointLight.position.set(0, 0, 0);
        scene.add(pointLight);

        // Create orb mesh
        const sphereGeometry = new THREE.IcosahedronGeometry(30, 4); // Higher detail icosahedron
        const sphereMaterial = new THREE.MeshPhongMaterial({
            color: 0x0088ff,
            emissive: 0x222222,
            shininess: 30,
            wireframe: false,
            flatShading: true
        });
        const sphere = new THREE.Mesh(sphereGeometry, sphereMaterial);
        scene.add(sphere);

        // Store original vertex positions
        const originalVertices = [];
        for (let i = 0; i < sphereGeometry.attributes.position.count; i++) {
            originalVertices.push(
                new THREE.Vector3(
                    sphereGeometry.attributes.position.getX(i),
                    sphereGeometry.attributes.position.getY(i),
                    sphereGeometry.attributes.position.getZ(i)
                )
            );
        }

        // Create a glow effect
        const glowGeometry = new THREE.SphereGeometry(32, 32, 32);
        const glowMaterial = new THREE.MeshBasicMaterial({
            color: 0x0088ff,
            transparent: true,
            opacity: 0.15,
            side: THREE.BackSide
        });
        const glowMesh = new THREE.Mesh(glowGeometry, glowMaterial);
        scene.add(glowMesh);

        // Define rotation speed variables
        let rotationSpeedY = 0.002;
        let rotationSpeedX = 0.001;
        let isGenerating = false;

        // Tab functionality
        function openTab(evt, tabName) {
            // Hide all tabcontent
            const tabcontent = document.getElementsByClassName("tabcontent");
            for (let i = 0; i < tabcontent.length; i++) {
                tabcontent[i].style.display = "none";
            }

            // Remove active class from all tablinks
            const tablinks = document.getElementsByClassName("tablinks");
            for (let i = 0; i < tablinks.length; i++) {
                tablinks[i].className = tablinks[i].className.replace(" active", "");
            }

            // Show the current tab and add active class to the button
            document.getElementById(tabName).style.display = "block";
            evt.currentTarget.className += " active";
            if (tabName != "speechToSpeech") {
                closeWebRTCStream();
            }
        }

        // Speed slider update
        speedInput.addEventListener('input', function() {
            speedValue.textContent = this.value;
        });

        // Generate speech button handler
        generateBtn.addEventListener('click', function() {
            const text = textInput.value;
            const language = languageSelect.value;
            const voice = voiceSelect.value;
            const model = modelSelect.value;
            
            // Get speed based on model type
            let speed;
            if (modelTypeSelect.value === 'spark') {
                speed = document.getElementById('sparkSpeed').value;
            } else {
                speed = speedInput.value;
            }

            if (!text.trim()) {
                showTtsError('Please enter some text');
                return;
            }

            // Hide previous error
            ttsErrorElement.style.display = 'none';
            ttsStatusElement.textContent = 'Generating speech...';

            // Increase rotation speed to indicate processing
            isGenerating = true;
            rotationSpeedY = 0.01;
            rotationSpeedX = 0.005;

            // Create form data
            const formData = new FormData();
            formData.append('text', text);
            formData.append('model', model);
            formData.append('speed', speed);
            
            // Add pitch and gender for Spark models
            if (modelTypeSelect.value === 'spark') {
                const pitch = document.getElementById('sparkPitch').value;
                const gender = document.getElementById('sparkGender').value;
                formData.append('pitch', pitch);
                formData.append('gender', gender);
            }
            
            // Add model-specific parameters
            const selectedType = modelTypeSelect.value;
            const config = modelConfigs[selectedType];
            
            if (config.supportsVoices) {
                formData.append('voice', voice);
            }
            
            if (config.supportsLanguages) {
                formData.append('language', language);
            }
            
            if (config.supportsReferenceAudio && referenceAudioInput.files.length > 0) {
                formData.append('reference_audio', referenceAudioInput.files[0]);
            }

            // Send request to server
            fetch('/tts', {
                method: 'POST',
                body: formData
            })
            .then(response => {
                if (!response.ok) {
                    return response.json().then(data => {
                        throw new Error(data.error || 'Failed to generate speech');
                    });
                }
                return response.json();
            })
            .then(data => {
                ttsStatusElement.textContent = 'Speech generated successfully!';

                // Reset rotation speed
                isGenerating = false;
                rotationSpeedY = 0.002;
                rotationSpeedX = 0.001;

                // Clean up previous audio resources
                if (audioElement) {
                    audioElement.pause();
                    audioElement.removeAttribute('src');
                }

                if (audioSource) {
                    audioSource.disconnect();
                    audioSource = null; // Reset the variable explicitly
                }
                // Recreate audioElement to avoid potential issues with re-using the same element
                // This helps ensure createMediaElementSource works consistently.
                const oldAudioElement = document.getElementById('audioElement');
                if (oldAudioElement) {
                    oldAudioElement.remove();
                }
                audioElement = document.createElement('audio');
                audioElement.id = 'audioElement';
                audioElement.autoplay = false; // Don't autoplay immediately
                audioElement.style.display = 'none';
                document.getElementById('controls').appendChild(audioElement);

                // Set audio source with absolute path
                audioElement.src = `/audio/${data.filename}`;
                audioElement.loop = false;

                // Enable play button
                playBtn.disabled = false;
                stopBtn.disabled = true;

                // Add ended event listener
                audioElement.addEventListener('ended', function() {
                    statusElement.textContent = "Audio finished playing.";
                    playBtn.disabled = false;
                    stopBtn.disabled = true;
                    resetSphere();
                });

                // Auto-play the generated audio
                playAudio(); // playAudio will now create a fresh connection
            })
            .catch(error => {
                showTtsError(error.message);

                // Reset rotation speed on error too
                isGenerating = false;
                rotationSpeedY = 0.002;
                rotationSpeedX = 0.001;
            });
        });

        // Open output folder button handler
        openFolderBtn.addEventListener('click', function() {
            fetch('/open_output_folder', {
                method: 'POST'
            })
            .then(response => {
                if (!response.ok) {
                    return response.json().then(data => {
                        throw new Error(data.error || 'Failed to open output folder');
                    });
                }
                return response.json();
            })
            .then(data => {
                ttsStatusElement.textContent = `Opened output folder: ${data.path}`;
            })
            .catch(error => {
                showTtsError(error.message);
            });
        });

        function showTtsError(message) {
            ttsErrorElement.textContent = message;
            ttsErrorElement.style.display = 'block';
        }

        // Function to play audio (reused for both upload and TTS)
        function playAudio() {
            if (!audioElement || !audioElement.src) {
                statusElement.textContent = "No audio available to play.";
                return;
            }

            statusElement.textContent = "Playing audio...";

            // Initialize audio context if needed
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }

            // Create analyser if needed
            if (!analyser) {
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                dataArray = new Uint8Array(analyser.frequencyBinCount);
            }

            // Connect audio element to analyser if not already connected
            if (!audioSource) {
                try {
                    audioSource = audioContext.createMediaElementSource(audioElement);
                    audioSource.connect(analyser);
                    analyser.connect(audioContext.destination);
                } catch (error) {
                    console.error("Error connecting audio source:", error);
                    statusElement.textContent = "Error setting up audio visualization. Try refreshing the page.";

                    // Still try to play the audio even if visualization fails
                    audioElement.play().catch(playError => {
                        statusElement.textContent = "Error playing audio: " + playError.message;
                    });
                    return;
                }
            }

            // Play audio
            audioElement.play().then(() => {
                playBtn.disabled = true;
                stopBtn.disabled = false;
            }).catch(error => {
                statusElement.textContent = "Error playing audio: " + error.message;
            });
        }

        // Handle audio upload
        audioUpload.addEventListener('change', function(e) {
            const file = e.target.files[0];
            if (!file) return;

            statusElement.textContent = "Audio file loaded. Press Play to start.";

            // Clean up previous audio resources
            if (audioElement) {
                audioElement.pause();
                audioElement.removeAttribute('src');
            }

            if (audioSource) {
                audioSource.disconnect();
                audioSource = null; // Reset the variable explicitly
            }

            // Recreate audioElement to avoid potential issues with re-using the same element
            // This helps ensure createMediaElementSource works consistently.
            const oldAudioElement = document.getElementById('audioElement');
            if (oldAudioElement) {
                oldAudioElement.remove();
            }
            audioElement = document.createElement('audio');
            audioElement.id = 'audioElement';
            audioElement.autoplay = false; // Don't autoplay immediately
            audioElement.style.display = 'none';
            document.getElementById('controls').appendChild(audioElement);

            audioElement.src = URL.createObjectURL(file);
            audioElement.loop = false;

            // Enable play button
            playBtn.disabled = false;
            stopBtn.disabled = true;

            // Add ended event listener
            audioElement.addEventListener('ended', function() {
                statusElement.textContent = "Audio finished playing.";
                playBtn.disabled = false;
                stopBtn.disabled = true;
                resetSphere();
            });
        });

        // Play button handler
        playBtn.addEventListener('click', function() {
            playAudio();
        });

        // Stop button handler
        stopBtn.addEventListener('click', function() {
            if (audioElement) {
                audioElement.pause();
                audioElement.currentTime = 0;
                statusElement.textContent = "Audio stopped. Press Play to restart.";
                playBtn.disabled = false;
                stopBtn.disabled = true;

                // Reset sphere to original state
                resetSphere();
            }
        });

        // Reset sphere to original state
        function resetSphere() {
            const positionAttribute = sphereGeometry.attributes.position;

            for (let i = 0; i < positionAttribute.count; i++) {
                const originalVertex = originalVertices[i];
                positionAttribute.setXYZ(i, originalVertex.x, originalVertex.y, originalVertex.z);
            }

            positionAttribute.needsUpdate = true;
            sphereGeometry.computeVertexNormals();

            // Reset colors
            sphere.material.color.set(0x0088ff);
            sphere.material.emissive.set(0x222222);
            glowMesh.material.color.set(0x0088ff);
        }

        // Animation loop
        function  animate() {
            requestAnimationFrame(animate);

            // Update controls
            controls.update();

            // Get current time for pulsating effect
            const time = performance.now() * 0.001; // Convert to seconds

            // Rotate sphere with current speed
            sphere.rotation.y += rotationSpeedY;
            sphere.rotation.x += rotationSpeedX;
            glowMesh.rotation.copy(sphere.rotation);

            // Update visualization if audio is playing
            if (analyser && dataArray && !audioElement.paused) {
                analyser.getByteFrequencyData(dataArray);

                // Calculate average frequency values for different ranges
                const bassAvg = getAverageFrequency(dataArray, 0, 5);
                const midAvg = getAverageFrequency(dataArray, 6, 20);
                const trebleAvg = getAverageFrequency(dataArray, 21, 40);

                // Calculate base pulsating factor (same as when no audio is playing)
                const pulseFactor = Math.sin(time * 1.5) * 0.03 + 1; // Subtle pulsation (Â±3%)

                // Update sphere vertices based on frequency data
                const positionAttribute = sphereGeometry.attributes.position;

                for (let i = 0; i < positionAttribute.count; i++) {
                    const originalVertex = originalVertices[i];

                    // Calculate normalized distance from center (0-1)
                    const vertexLength = originalVertex.length();

                    // Get frequency value based on vertex position
                    let frequencyFactor;

                    // Use different frequency ranges based on vertex position
                    if (Math.abs(originalVertex.y) > vertexLength * 0.7) {
                        // Top/bottom vertices - use treble
                        frequencyFactor = trebleAvg / 255;
                    } else if (Math.abs(originalVertex.x) > vertexLength * 0.7) {
                        // Left/right vertices - use mids
                        frequencyFactor = midAvg / 255;
                    } else {
                        // Other vertices - use bass
                        frequencyFactor = bassAvg / 255;
                    }

                    // Scale vertex based on both pulsation and frequency
                    // First apply the pulsating effect, then add audio reactivity
                    const scaleFactor = pulseFactor * (1 + frequencyFactor * 0.5);

                    positionAttribute.setXYZ(
                        i,
                        originalVertex.x * scaleFactor,
                        originalVertex.y * scaleFactor,
                        originalVertex.z * scaleFactor
                    );
                }

                positionAttribute.needsUpdate = true;
                sphereGeometry.computeVertexNormals();

                // Update colors based on frequency
                const hue = (bassAvg / 255) * 0.3;
                const saturation = 0.8;
                const lightness = 0.4 + (midAvg / 255) * 0.2;

                sphere.material.color.setHSL(hue, saturation, lightness);
                sphere.material.emissive.setHSL(hue, saturation, lightness * 0.5);

                // Update glow with both pulsation and audio reactivity
                glowMesh.material.color.setHSL(hue, saturation, lightness);
                const glowPulseFactor = 1 + Math.sin(time * 1.2) * 0.04;
                glowMesh.scale.set(
                    glowPulseFactor * (1 + (bassAvg / 255) * 0.1),
                    glowPulseFactor * (1 + (bassAvg / 255) * 0.1),
                    glowPulseFactor * (1 + (bassAvg / 255) * 0.1)
                );

                // Update point light with both pulsation and audio reactivity
                const lightPulseFactor = 0.5 + Math.sin(time * 1.8) * 0.2;
                pointLight.intensity = lightPulseFactor + (bassAvg / 255) * 1.5;
                pointLight.color.setHSL(hue, saturation, lightness);
            } else {
                // Apply subtle pulsating effect when no audio is playing
                const pulseFactor = Math.sin(time * 1.5) * 0.03 + 1; // Subtle pulsation (Â±3%)

                // Update sphere vertices for pulsating effect
                const positionAttribute = sphereGeometry.attributes.position;

                for (let i = 0; i < positionAttribute.count; i++) {
                    const originalVertex = originalVertices[i];

                    positionAttribute.setXYZ(
                        i,
                        originalVertex.x * pulseFactor,
                        originalVertex.y * pulseFactor,
                        originalVertex.z * pulseFactor
                    );
                }

                positionAttribute.needsUpdate = true;
                sphereGeometry.computeVertexNormals();

                // Subtle color pulsation
                const hue = 0.6; // Blue hue
                const saturation = 0.8;
                const lightness = 0.4 + Math.sin(time * 2) * 0.05; // Subtle brightness pulsation

                sphere.material.color.setHSL(hue, saturation, lightness);
                sphere.material.emissive.setHSL(hue, saturation, lightness * 0.5);

                // Update glow with subtle pulsation
                glowMesh.material.color.setHSL(hue, saturation, lightness);
                glowMesh.scale.set(
                    1 + Math.sin(time * 1.2) * 0.04, // Slightly different frequency for interesting effect
                    1 + Math.sin(time * 1.2) * 0.04,
                    1 + Math.sin(time * 1.2) * 0.04
                );

                // Subtle point light pulsation
                pointLight.intensity = 0.5 + Math.sin(time * 1.8) * 0.2;
                pointLight.color.setHSL(hue, saturation, lightness);
            }

            renderer.render(scene, camera);
        }

        // Helper function to get average frequency in a range
        function getAverageFrequency(dataArray, startIndex, endIndex) {
            let sum = 0;
            for (let i = startIndex; i <= endIndex; i++) {
                sum += dataArray[i];
            }
            return sum / (endIndex - startIndex + 1);
        }

        // Handle window resize
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });

        // Start animation loop
        animate();

        // WebRTC variables
        let webrtcConnection = null;
        let webrtcId = null;
        let dataChannel = null;
        let analyzer = null;

        // Speech to Speech functionality
        document.getElementById('s2sSpeed').addEventListener('input', function() {
            document.getElementById('s2sSpeedValue').textContent = this.value + 'x';
        });

        document.getElementById('startStreamBtn').addEventListener('click', function() {
            if (!webrtcConnection) {
                startWebRTCStream();
                this.textContent = "Connecting...";
                this.disabled = true;
            } else {
                closeWebRTCStream();
                this.textContent = "Start Stream";
                this.classList.remove('streaming');
            }
        });

        async function startWebRTCStream() {
            try {
                const streamStatus = document.getElementById('streamStatus');
                streamStatus.textContent = "Initializing connection...";

                // Get user media for microphone
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

                // Create RTCPeerConnection
                webrtcConnection = new RTCPeerConnection({});

                // Add local stream tracks to connection
                stream.getAudioTracks().forEach(track => {
                    webrtcConnection.addTrack(track, stream);
                });

                // Set up data channel
                dataChannel = webrtcConnection.createDataChannel("text");
                dataChannel.onopen = handleDataChannelOpen;
                dataChannel.onmessage = handleDataChannelMessage;
                dataChannel.onclose = () => {
                    console.log("Data channel closed");
                };

                // Handle ICE candidate events
                webrtcConnection.onicecandidate = event => {
                    if (event.candidate) {
                        // We'll handle ICE candidates in the offer
                    }
                };

                // Handle track events for receiving audio
                webrtcConnection.ontrack = event => {
                    const remoteStream = new MediaStream();
                    event.streams[0].getTracks().forEach(track => {
                        remoteStream.addTrack(track);
                    });

                    if (!audioContext) {
                        audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    }

                    if (audioSource) {
                        audioSource.disconnect();
                    }

                    audioSource = audioContext.createMediaStreamSource(remoteStream);

                    if (!analyser) {
                        analyser = audioContext.createAnalyser();
                        analyser.fftSize = 256;
                        dataArray = new Uint8Array(analyser.frequencyBinCount);
                    }

                    audioSource.connect(analyser);
                    analyser.connect(audioContext.destination);

                    audioElement.srcObject = remoteStream;
                    audioElement.play();
                };

                // Create offer
                const offer = await webrtcConnection.createOffer({
                    offerToReceiveAudio: true,
                    offerToReceiveVideo: false
                });

                await webrtcConnection.setLocalDescription(offer);

                // Wait for ICE gathering to complete
                await new Promise(resolve => {
                    if (webrtcConnection.iceGatheringState === 'complete') {
                        resolve();
                    } else {
                        webrtcConnection.addEventListener('icegatheringstatechange', () => {
                            if (webrtcConnection.iceGatheringState === 'complete') {
                                resolve();
                            }
                        });
                    }
                });

                // Send offer to server
                const response = await fetch('/webrtc/offer', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        sdp: webrtcConnection.localDescription.sdp,
                        type: webrtcConnection.localDescription.type,
                        webrtc_id: generateWebRTCId(),
                    }),
                });

                const responseData = await response.json();

                if (responseData.status === 'failed') {
                    throw new Error(responseData.meta?.error || 'Connection failed');
                }

                // Set remote description
                await webrtcConnection.setRemoteDescription(new RTCSessionDescription({
                    type: 'answer',
                    sdp: responseData.sdp,
                }));

                streamStatus.textContent = "Connecting...";

            } catch (error) {
                console.error('Error starting WebRTC stream:', error);
                document.getElementById('streamStatus').textContent = "Error: " + error.message;
                document.getElementById('startStreamBtn').disabled = false;
                document.getElementById('startStreamBtn').textContent = "Start Stream";
                closeWebRTCStream();
            }
        }

        function handleDataChannelOpen() {
            console.log("Data channel opened!");
            const streamStatus = document.getElementById('streamStatus');
            streamStatus.textContent = "Connected! Speak into your microphone.";

            const startStreamBtn = document.getElementById('startStreamBtn');
            startStreamBtn.disabled = false;
            startStreamBtn.textContent = "Close Stream";
            startStreamBtn.classList.add('streaming');

            // Send initial configuration
            sendInputConfiguration();
        }

        function handleDataChannelMessage(event) {
            try {
                const message = JSON.parse(event.data);
                console.log("Received message:", message);

                if (message.type === 'send_input') {
                    // Server is requesting updated input parameters
                    sendInputConfiguration();
                } else if (message.type === 'error') {
                    document.getElementById('streamStatus').textContent = "Error: " + message.data;
                } else if (message.type === 'log') {
                    // Handle different log types
                    if (message.data === 'pause_detected') {
                        document.getElementById('streamStatus').textContent = "Pause detected, processing...";
                    } else if (message.data === 'response_starting') {
                        document.getElementById('streamStatus').textContent = "Generating response...";
                    } else if (message.data === 'started_talking') {
                        document.getElementById('streamStatus').textContent = "Speaking...";
                    }
                }
            } catch (e) {
                console.error("Error parsing message:", e);
            }
        }

        function sendInputConfiguration() {
            if (!dataChannel || dataChannel.readyState !== 'open') return;

            // Get current configuration values
            const voice = document.getElementById('s2sVoice').value;
            const model = document.getElementById('s2sModel').value;
            const speed = parseFloat(document.getElementById('s2sSpeed').value);

            // Send POST request to the specified endpoint
            fetch('/speech_to_speech_input', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    voice: voice,
                    model: model,
                    speed: speed,
                    webrtc_id: webrtcId
                })
            }).catch(error => {
                console.error('Error sending configuration:', error);
            });
        }

        function closeWebRTCStream() {
            if (webrtcConnection) {
                webrtcConnection.close();
                webrtcConnection = null;
            }

            if (dataChannel) {
                dataChannel.close();
                dataChannel = null;
            }
            dataChannel = null;
            analyzer = null;

            document.getElementById('streamStatus').textContent = "";
            webrtcId = null;
            audioContext = null;
            analyser = null;
            audioSource = null;
        }

        function generateWebRTCId() {
            webrtcId = 'webrtc-' + Date.now() + '-' + Math.floor(Math.random() * 1000000);
            return webrtcId;
        }

        // Initialize on page load
        async function initialize() {
            // Fetch models from server
            await fetchModels();
            
            // Initialize tabs
            const defaultTab = document.getElementsByClassName("tablinks")[0];
            defaultTab.click();
        }
        
        // Start initialization when DOM is ready
        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', initialize);
        } else {
            initialize();
        }
    </script>
</body>
</html>